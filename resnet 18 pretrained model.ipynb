{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "aa2c70f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a1b7ede0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "eb950147",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9ccb56ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b5b5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## download the dataset from the following link below\n",
    "#  https://www.kaggle.com/datasets/misrakahmed/vegetable-image-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bb8b2265",
   "metadata": {},
   "outputs": [],
   "source": [
    "class training(Dataset):\n",
    "    def __init__(self,path,transform=None):\n",
    "        self.path=path   \n",
    "        self.transform=transform\n",
    "        image=[]\n",
    "        label=[]\n",
    "        classes=[]\n",
    "        length=len(image)\n",
    "        self.calsses=classes\n",
    "        for i in os.listdir(path):\n",
    "            path1=os.path.join(path,i)\n",
    "            classes.append(i)\n",
    "            for j in os.listdir(path1):\n",
    "                img_path=os.path.join(path1,j)\n",
    "                image.append(img_path)\n",
    "                x=classes.index(i)\n",
    "                label.append(x)\n",
    "        self.images=image\n",
    "        self.labels=label\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    def __getitem__(self,idx):\n",
    "        image_path=self.images[idx]\n",
    "        image=cv2.imread(image_path)\n",
    "        image=cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "        target=self.labels[idx]\n",
    "        if self.transform is not None:\n",
    "            image=self.transform(image)\n",
    "            target=np.eye(15)[target] ##always use one-hot encoding for crossentropy loss function\n",
    "        label=torch.tensor([target])\n",
    "        return image,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0fa21d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "  transforms.ToTensor(),\n",
    "  transforms.Resize((100, 100)),\n",
    "  transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "955b82db",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=training(r\"F:\\datasets\\Vegetable Images\\train\",transform=train_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f0d8c876",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = torch.utils.data.random_split(dataset,[10000,5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c15e088a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_set, batch_size=30,shuffle=True)\n",
    "test_dataloader = DataLoader(test_set, batch_size=1,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9637314",
   "metadata": {},
   "source": [
    "## loading the pretrained model from pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "14b14af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853e0cfa",
   "metadata": {},
   "source": [
    "## suppose if you are doing N classes classification then output features in the last linear layer must be N."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bd2a6e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc=Linear(in_features=512, out_features=15, bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4d12cc0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=15, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a04ffa24",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device=device) \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr= 0.001) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a492b14",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9473d4ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 15000/15000 [45:21<00:00,  5.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss 25488.403936794857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "MAX_EPOCHS = 1\n",
    "for epoch in range(MAX_EPOCHS):\n",
    "    running_loss = 0.0\n",
    "    for input_tensor, labels in tqdm(dataset_loader):\n",
    "        images = input_tensor.to(device).float()\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels[0])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()/30 #(30=batchsize)\n",
    "    print('epoch', epoch, 'loss', running_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b206debf",
   "metadata": {},
   "source": [
    "## Testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4384fb36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 5000/5000 [02:21<00:00, 35.30it/s]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "ground_truth=[]\n",
    "predection=[]\n",
    "for img,label in tqdm(test_dataloader):\n",
    "    output=model(img.to(device).float())\n",
    "    target=label.to(device)\n",
    "    output=torch.argmax(output).data.cpu().numpy() #the output is in tensors format.so,we are changing it to arrays to process the data in sklearn\n",
    "    target=torch.argmax(target).data.cpu().numpy()\n",
    "    ground_truth.append(target)\n",
    "    predection.append(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b72625",
   "metadata": {},
   "source": [
    "## classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5583a6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,classification_report,f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "30df8440",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[160,  87,   0,  15,  49,   4,   0,   0,   6,  16,   0,   0,   1,\n",
       "          3,   3],\n",
       "       [  1, 327,   1,  10,   0,   0,   0,   0,   0,   3,   2,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,  29, 289,   3,   5,   4,   0,   0,   0,   0,  25,   0,   1,\n",
       "          0,   0],\n",
       "       [  0,  38,   2, 225,   8,   5,   0,   0,   2,   2,  11,   0,   7,\n",
       "          1,   0],\n",
       "       [  1,   4,   0,   4, 282,   4,   0,   0,   6,   0,   1,   0,   7,\n",
       "          0,   0],\n",
       "       [  0,   6,   0,  21,  25, 242,   0,   0,   7,   0,   4,   0,  39,\n",
       "          0,   2],\n",
       "       [  1,   3,   2,   1,   4,   1, 303,  13,   0,   0,   5,   4,   2,\n",
       "          8,   3],\n",
       "       [  0,   0,   0,   0,   0,   0,   0, 319,   1,   0,   0,   3,   3,\n",
       "          6,   0],\n",
       "       [  1,   1,   0,   2,  16,   7,   0,   0, 297,   0,   1,   5,  16,\n",
       "          3,   0],\n",
       "       [  3,  73,   1,  23,   1,   0,   1,   0,   1, 225,   1,   0,   3,\n",
       "          1,   2],\n",
       "       [  0,  22,   2,   4,   1,   1,   1,   0,   0,   2, 288,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   3,   2,   0,   0, 318,   8,\n",
       "          7,   0],\n",
       "       [  0,   4,   0,   3,  26,   7,   1,   0,  11,   1,   0,   1, 279,\n",
       "          6,   0],\n",
       "       [  0,   3,   0,   6,   0,   0,   0,   0,  11,   0,   0,   2,   2,\n",
       "        289,   0],\n",
       "       [  1,  12,   4,  15,   4,   6,   5,   6,  13,   5,   5,  12,  16,\n",
       "          9, 210]], dtype=int64)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#x=confusion_matrix(df1['ground_truth'],df1['predections'])\n",
    "confusion_matrix(ground_truth, predection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6e9883a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.47      0.62       344\n",
      "           1       0.54      0.95      0.69       344\n",
      "           2       0.96      0.81      0.88       356\n",
      "           3       0.68      0.75      0.71       301\n",
      "           4       0.67      0.91      0.77       309\n",
      "           5       0.86      0.70      0.77       346\n",
      "           6       0.97      0.87      0.92       350\n",
      "           7       0.94      0.96      0.95       332\n",
      "           8       0.83      0.85      0.84       349\n",
      "           9       0.89      0.67      0.76       335\n",
      "          10       0.84      0.90      0.87       321\n",
      "          11       0.92      0.94      0.93       338\n",
      "          12       0.73      0.82      0.77       339\n",
      "          13       0.87      0.92      0.89       313\n",
      "          14       0.95      0.65      0.77       323\n",
      "\n",
      "    accuracy                           0.81      5000\n",
      "   macro avg       0.84      0.81      0.81      5000\n",
      "weighted avg       0.84      0.81      0.81      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(ground_truth,predection))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "21c5b148",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8106"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(ground_truth,predection,average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ce7c55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d101a61e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
